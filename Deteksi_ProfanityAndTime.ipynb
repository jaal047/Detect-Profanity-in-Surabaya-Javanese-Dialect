{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "o4-c6LT3l32H"
   },
   "outputs": [],
   "source": [
    "#pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "T11ePHOYOOlQ"
   },
   "outputs": [],
   "source": [
    "#pip install yt-dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "nl8R4gJLOXEF"
   },
   "outputs": [],
   "source": [
    "#!apt-get install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uS8qhP3fpoJy"
   },
   "outputs": [],
   "source": [
    "#pip install pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LYRpCsePqvrJ"
   },
   "outputs": [],
   "source": [
    "#pip install noisereduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "l9IO0zSoqncw"
   },
   "outputs": [],
   "source": [
    "#pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "WbiILTOOq-HT"
   },
   "outputs": [],
   "source": [
    "#pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cEPErCS7ltWk"
   },
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.effects import normalize\n",
    "import torch\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "import torchaudio\n",
    "import os\n",
    "from pytube import YouTube\n",
    "from moviepy.editor import VideoFileClip\n",
    "import subprocess\n",
    "import noisereduce as nr\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "import librosa\n",
    "import scipy.signal\n",
    "from datasets import load_dataset, load_metric\n",
    "import jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cph3he_FG7Ff",
    "outputId": "99826b08-9920-433b-f3a4-c4c5c2415fe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bitrate dari file lucu.wav:  bits per second\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Path ke file audio\n",
    "audio_file_path = 'lucu.wav'\n",
    "\n",
    "# Fungsi untuk mendapatkan bitrate menggunakan ffprobe\n",
    "def get_audio_bitrate(audio_file_path):\n",
    "    result = subprocess.run(\n",
    "        ['ffprobe', '-v', 'error', '-show_entries', 'format=bit_rate', '-of', 'default=noprint_wrappers=1:nokey=1', audio_file_path],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE\n",
    "    )\n",
    "    return result.stdout.decode('utf-8').strip()\n",
    "\n",
    "# Mendapatkan bitrate\n",
    "bitrate = get_audio_bitrate(audio_file_path)\n",
    "print(f\"Bitrate dari file {audio_file_path}: {bitrate} bits per second\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x5Ki8yERmET8",
    "outputId": "00956dce-b126-426c-c273-2e8d43cd071c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uxunYd0Y0ZK2",
    "outputId": "89727b65-39a8-49e7-f9fb-48de14cfaed0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Load model dan processor\n",
    "model_path = \"/content/drive/MyDrive/Skripsi/wav2vec2-profanity-javanese-sby\"\n",
    "#model_path = \"indonesian-nlp/wav2vec2-indonesian-javanese-sundanese\"\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_path)\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-aduA4qK0mS"
   },
   "source": [
    "# **Scraping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DffZ7pryKymD",
    "outputId": "d2c5c109-e879-4b19-fa0e-020ece2cc3e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/shorts/Lvl_EsR0og4\n",
      "[youtube] Lvl_EsR0og4: Downloading webpage\n",
      "[youtube] Lvl_EsR0og4: Downloading ios player API JSON\n",
      "[youtube] Lvl_EsR0og4: Downloading android player API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] Skipping player responses from android clients (got player responses for video \"aQvGIIdgFDM\" instead of \"Lvl_EsR0og4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Lvl_EsR0og4: Downloading player 018e9916\n",
      "[youtube] Lvl_EsR0og4: Downloading m3u8 information\n",
      "[info] Lvl_EsR0og4: Downloading 1 format(s): 251\n",
      "[download] Destination: downloaded_audio\n",
      "[download] 100% of  525.71KiB in 00:00:00 at 4.25MiB/s   \n",
      "[ExtractAudio] Destination: downloaded_audio.wav\n",
      "Deleting original file downloaded_audio (pass -k to keep)\n",
      "Audio telah berhasil diunduh dan dikonversi ke format WAV dengan kualitas optimal.\n"
     ]
    }
   ],
   "source": [
    "import yt_dlp\n",
    "import subprocess\n",
    "\n",
    "# URL video YouTube\n",
    "youtube_url = \"https://www.youtube.com/shorts/Lvl_EsR0og4\"\n",
    "\n",
    "# Fungsi untuk mengunduh audio menggunakan yt-dlp\n",
    "def download_audio(youtube_url, output_path):\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'outtmpl': output_path,  # Path file output sementara\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'wav',  # Format audio yang diinginkan (WAV)\n",
    "            'preferredquality': '320',  # Kualitas audio output (opsional)\n",
    "        }],\n",
    "    }\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([youtube_url])\n",
    "\n",
    "# Path file output sementara dan output akhir\n",
    "temp_audio_path = 'downloaded_audio'\n",
    "audio_output_path = 'output_audio.wav'\n",
    "\n",
    "# Unduh audio dari YouTube\n",
    "download_audio(youtube_url, temp_audio_path)\n",
    "\n",
    "# Meningkatkan kualitas audio menggunakan ffmpeg\n",
    "subprocess.run([\n",
    "    'ffmpeg', '-i', temp_audio_path,\n",
    "    '-ar', '44100', '-ac', '2', '-b:a', '1411k', audio_output_path\n",
    "])\n",
    "\n",
    "print(\"Audio telah berhasil diunduh dan dikonversi ke format WAV dengan kualitas optimal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-n9fTmSBKz2c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijJVQuGWj6nn"
   },
   "source": [
    "# **Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "voDYCiJicRf6",
    "outputId": "d89050ce-03dc-4a6c-8edd-3e43c4eea6c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil noise reduction disimpan di: audio_reduced_noise.wav\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import noisereduce as nr\n",
    "import soundfile as sf\n",
    "\n",
    "# Memuat file audio\n",
    "file_audio_path = 'audio_1.wav'\n",
    "y, sr = librosa.load(file_audio_path, sr=16000)\n",
    "\n",
    "# Mengurangi noise\n",
    "reduced_noise = nr.reduce_noise(y=y, sr=sr)\n",
    "\n",
    "# Menyimpan file audio hasil noise reduction\n",
    "output_file_path = 'audio_reduced_noise.wav'\n",
    "sf.write(output_file_path, reduced_noise, sr)\n",
    "\n",
    "print(f\"Hasil noise reduction disimpan di: {output_file_path}\")\n",
    "# Fungsi untuk memuat dan preprocess audio\n",
    "def load_and_preprocess_audio(file_path):\n",
    "    audio_array, sampling_rate = torchaudio.load(file_path)\n",
    "\n",
    "    # Resample audio jika sampling rate tidak 16000\n",
    "    if sampling_rate != 16000:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sampling_rate, new_freq=16000)\n",
    "        audio_array = resampler(audio_array)\n",
    "\n",
    "    # Volume normalization\n",
    "    volume_transform = torchaudio.transforms.Vol(gain=1.0, gain_type='amplitude')\n",
    "    audio_array = volume_transform(audio_array)\n",
    "\n",
    "    audio_array = audio_array.squeeze().numpy()\n",
    "    return audio_array\n",
    "\n",
    "# Path ke file audio\n",
    "audio_path = \"/content/audio_reduced_noise.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "EjaTvs3Hca1t"
   },
   "outputs": [],
   "source": [
    "# Muat dan preprocess audio\n",
    "audio_array = load_and_preprocess_audio(audio_path)\n",
    "\n",
    "# Preprocess audio dengan processor\n",
    "inputs = processor(audio_array, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "# Model inferensi\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs.input_values).logits\n",
    "\n",
    "# Ambil argmax dari logits untuk mendapatkan prediksi ID\n",
    "predicted_ids = torch.argmax(logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zca832TUcebL",
    "outputId": "6cd62dd4-6067-4dd9-c4f0-6bb45d986bcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transkripsi: seng gudu mbola koni gae njawab pertanyaan ngeri pas leparan koen kudu menjawab dengan baik rama dan sopan kapen rabi jancok krame kan cok jancok ra ba koen kudu menjawab dengan ngegas didu ono lek awakmu ngamu benwongi wedi kapan lonusuula koen kudu mengalihkan perhatian kerjo munah embi saiki lo gacok penapakan ji cok ndedi la penlambakan pakean seape sribu kiro kiro koen cik seeles dadi mbngapil belappak aokno sekg gurukno kiro kiro koen buduk tik surunan farat opo maneh cules nang gomenter hah\n"
     ]
    }
   ],
   "source": [
    "# Dekode prediksi ID menjadi teks\n",
    "transcription = processor.batch_decode(predicted_ids)[0]\n",
    "\n",
    "print(\"Transkripsi:\", transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "bFAX-z5uqhcL"
   },
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_wer(predictions, references):\n",
    "    error = jiwer.wer(references, predictions)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fdmz9NJbsSFK",
    "outputId": "47abb6f2-caf8-4bda-cdeb-a4324eeab3c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transkripsi: sen gudu mbok la koen igae njawab pertanyaan ngeri pas lebaran koen gudu menjawab dengan baik ramah dan sopan kapen rabi jancok kra mee cancok cancok ra bek koen kudumen jawab dengan ngegas dudu kono oleh awakmu ngamuk baen uwongi wedi kapan lolus ukoen kuduk mengalih kan perhatian kerjo munah endi sa iki lo jancok penampakan bi cok ndene la penambahkan pakean setese ribuk kiro kiro koen tib s terus ga dikongkercol penoko konk ke urukno k kiro koro koen buduk tip surunon fokat opo maneh tules nang komenter e\n"
     ]
    }
   ],
   "source": [
    "# Fungsi untuk memuat dan preprocess audio\n",
    "def load_and_preprocess_audio1(file_path):\n",
    "    audio_array, sampling_rate = torchaudio.load(file_path)\n",
    "    if sampling_rate != 16000:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sampling_rate, new_freq=16000)\n",
    "        audio_array = resampler(audio_array)\n",
    "    audio_array = audio_array.squeeze().numpy()\n",
    "    return audio_array\n",
    "# Muat dan preprocess audio\n",
    "audio_array1 = load_and_preprocess_audio1('audio_1.wav')\n",
    "\n",
    "# Preprocess audio dengan processor\n",
    "inputs = processor(audio_array1, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "# Model inferensi\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs.input_values).logits\n",
    "\n",
    "# Ambil argmax dari logits untuk mendapatkan prediksi ID\n",
    "predicted_ids1 = torch.argmax(logits, dim=-1)\n",
    "# Dekode prediksi ID menjadi teks\n",
    "transcription1 = processor.batch_decode(predicted_ids1)[0]\n",
    "\n",
    "print(\"Transkripsi:\", transcription1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OQ1ZdJ8YjGQl",
    "outputId": "03283f2c-448b-413d-b078-70ab73338fee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n",
      "\n",
      "Some weights of the model checkpoint at indonesian-nlp/wav2vec2-indonesian-javanese-sundanese were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at indonesian-nlp/wav2vec2-indonesian-javanese-sundanese and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transkripsi: sing gudu molakoni kainjawab pertanyaan ngeripas leparankonkudu menjawab dengan baik ramah dan sopan kapan rabi canck pramere cack cacukrab kon kudu menjawab dengan ngegas dudu an oleh awakmu engamu benvrb wongi wedi kapan loluskonkuduh mengalihkan perhatian kerja munandikecacok penapakan bicuk janilah menamakan pagaian satu seribukegarokontiekirkron buduh tup surnon faktapemaneh tulis langgomenter\n"
     ]
    }
   ],
   "source": [
    "model_path = \"indonesian-nlp/wav2vec2-indonesian-javanese-sundanese\"\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_path)\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_path)\n",
    "# Fungsi untuk memuat dan preprocess audio\n",
    "def load_and_preprocess_audio1(file_path):\n",
    "    audio_array, sampling_rate = torchaudio.load(file_path)\n",
    "    if sampling_rate != 16000:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sampling_rate, new_freq=16000)\n",
    "        audio_array = resampler(audio_array)\n",
    "    audio_array = audio_array.squeeze().numpy()\n",
    "    return audio_array\n",
    "# Muat dan preprocess audio\n",
    "audio_array2 = load_and_preprocess_audio1('audio_1.wav')\n",
    "\n",
    "# Preprocess audio dengan processor\n",
    "inputs = processor(audio_array2, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "# Model inferensi\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs.input_values).logits\n",
    "\n",
    "# Ambil argmax dari logits untuk mendapatkan prediksi ID\n",
    "predicted_ids2 = torch.argmax(logits, dim=-1)\n",
    "# Dekode prediksi ID menjadi teks\n",
    "transcription2 = processor.batch_decode(predicted_ids2)[0]\n",
    "\n",
    "print(\"Transkripsi:\", transcription2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "sQLRZ0oDqfRx"
   },
   "outputs": [],
   "source": [
    "predictions1 = [transcription1]\n",
    "predictions = [transcription]\n",
    "predictions2 = [transcription2]\n",
    "references = [\"seng kudu mbok lakoni gae njawab pertanyaan ngeri pas lebaran koen kudu menjawab dengan baik ramah dan sopan kapan rabi jancok rame ae jancok jancok kabeh koen kudu menjawab dengan ngegas duduono lek awakmu ngamuk ben wonge wedi kapan lulus koen kudu mengalihkan perhatian kerjomu nang ndi saiki lo jancok penampakan endi cok ini lah penempakan paket seratus ribu kiro kiro koen tips kiro kiro koen butuh tips bermanfaat opo maneh tulis nang komentar ah\"]\n",
    "#references = [\"seng kudu mbok lakoni pas ketemu wong mokel koen kudu negur wonge kandanono iku perbuatan elek dancok anake sucipto mokel nggateli lo lo lo gak bahaya ta opo se oy gerang gableg brewoken mokel oy deloken rek mokel nang kebone cak syarul dukun ngisin ngisini warga kaliasin dan tegal sari raimu ojok rekam rekama ngono pengen oleh bojo ayu kelakuan mu ngene rabi ambek wet blimbing koen mengganggu privasi aku yo due prestasi tak rekam balik gak ngurus gak ngurus anake sucipto goblok sucipto babah deloken rek wong iki ngganggu privasi ne wong liyo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2Iu8nOGle_q",
    "outputId": "b502f5fb-41cf-48a9-f961-bc8643133f70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transkripsi: seng gudu mbola koni gae njawab pertanyaan ngeri pas leparan koen kudu menjawab dengan baik rama dan sopan kapen rabi jancok krame kan cok jancok ra ba koen kudu menjawab dengan ngegas didu ono lek awakmu ngamu benwongi wedi kapan lonusuula koen kudu mengalihkan perhatian kerjo munah embi saiki lo gacok penapakan ji cok ndedi la penlambakan pakean seape sribu kiro kiro koen cik seeles dadi mbngapil belappak aokno sekg gurukno kiro kiro koen buduk tik surunan farat opo maneh cules nang gomenter hah\n",
      "Word Error Rate: 0.5866666666666667\n",
      "Transkripsi: sen gudu mbok la koen igae njawab pertanyaan ngeri pas lebaran koen gudu menjawab dengan baik ramah dan sopan kapen rabi jancok kra mee cancok cancok ra bek koen kudumen jawab dengan ngegas dudu kono oleh awakmu ngamuk baen uwongi wedi kapan lolus ukoen kuduk mengalih kan perhatian kerjo munah endi sa iki lo jancok penampakan bi cok ndene la penambahkan pakean setese ribuk kiro kiro koen tib s terus ga dikongkercol penoko konk ke urukno k kiro koro koen buduk tip surunon fokat opo maneh tules nang komenter e\n",
      "Word Error Rate (without prep): 0.7333333333333333\n",
      "Transkripsi: sen gudu mbok la koen igae njawab pertanyaan ngeri pas lebaran koen gudu menjawab dengan baik ramah dan sopan kapen rabi jancok kra mee cancok cancok ra bek koen kudumen jawab dengan ngegas dudu kono oleh awakmu ngamuk baen uwongi wedi kapan lolus ukoen kuduk mengalih kan perhatian kerjo munah endi sa iki lo jancok penampakan bi cok ndene la penambahkan pakean setese ribuk kiro kiro koen tib s terus ga dikongkercol penoko konk ke urukno k kiro koro koen buduk tip surunon fokat opo maneh tules nang komenter e\n",
      "Word Error Rate (Model Wirawan): 0.76\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Transkripsi:\", transcription)\n",
    "wer = evaluate_wer(predictions, references)\n",
    "print(\"Word Error Rate:\", wer)\n",
    "\n",
    "print(\"Transkripsi:\", transcription1)\n",
    "wer1 = evaluate_wer(predictions1, references)\n",
    "print(\"Word Error Rate (without prep):\", wer1)\n",
    "\n",
    "print(\"Transkripsi:\", transcription1)\n",
    "wer2 = evaluate_wer(predictions2, references)\n",
    "print(\"Word Error Rate (Model Wirawan):\", wer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhla0qUcbYMD"
   },
   "source": [
    "# **Percobaan Evaluasi Data Real**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5XT0fnOsbXZf",
    "outputId": "36bc8cd4-375c-4d71-ad50-ff4406b27c37"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import noisereduce as nr\n",
    "import soundfile as sf\n",
    "import torchaudio\n",
    "import torch\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "import jiwer\n",
    "\n",
    "# Load model dan processor\n",
    "model_path = \"/content/drive/MyDrive/Skripsi/wav2vec2-profanity-javanese-sby\"\n",
    "#model_path = \"indonesian-nlp/wav2vec2-indonesian-javanese-sundanese\"\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_path)\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "dn0fyirobs9F"
   },
   "outputs": [],
   "source": [
    "# Fungsi untuk mengurangi noise dan menyimpan hasil\n",
    "def reduce_noise(input_path, output_path):\n",
    "    y, sr = librosa.load(input_path, sr=16000)\n",
    "    reduced_noise = nr.reduce_noise(y=y, sr=sr)\n",
    "    sf.write(output_path, reduced_noise, sr)\n",
    "    print(f\"Hasil noise reduction disimpan di: {output_path}\")\n",
    "\n",
    "# Fungsi untuk memuat dan preprocess audio\n",
    "def load_and_preprocess_audio(file_path):\n",
    "    audio_array, sampling_rate = torchaudio.load(file_path)\n",
    "    if sampling_rate != 16000:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sampling_rate, new_freq=16000)\n",
    "        audio_array = resampler(audio_array)\n",
    "    volume_transform = torchaudio.transforms.Vol(gain=1.0, gain_type='amplitude')\n",
    "    audio_array = volume_transform(audio_array)\n",
    "    audio_array = audio_array.squeeze().numpy()\n",
    "    return audio_array\n",
    "\n",
    "# Fungsi untuk memuat audio tanpa preprocessing\n",
    "def load_audio(file_path):\n",
    "    audio_array, sampling_rate = torchaudio.load(file_path)\n",
    "    if sampling_rate != 16000:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sampling_rate, new_freq=16000)\n",
    "        audio_array = resampler(audio_array)\n",
    "    audio_array = audio_array.squeeze().numpy()\n",
    "    return audio_array\n",
    "\n",
    "# Fungsi untuk melakukan inferensi dan transkripsi\n",
    "def transcribe_audio(audio_array):\n",
    "    inputs = processor(audio_array, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs.input_values).logits\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = processor.batch_decode(predicted_ids)[0]\n",
    "    return transcription\n",
    "\n",
    "# Fungsi untuk menghitung WER\n",
    "def evaluate_wer(predictions, references):\n",
    "    error = jiwer.wer(references, predictions)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gu3zRxlczHPq"
   },
   "outputs": [],
   "source": [
    " 'audio_3.wav', 'audio_4.wav', 'audio_5.wav'\n",
    " \"wah jancok subhanallah pakuwon mall bagus sekali wah hancok pakuwon guede cok sumpah yaallah deloken guede sumpah gak onok ngene iki nang sidoarjo cok jancok ye aku wes nang pakuwon mall ye aku wes nang pakuwon mall disini sangat berbeda dengan ramayan bunmurasih semunya terlihat mewah dan mahal aku disini merasa miskin buanget cok aku sampai tidak mampu membeli makanan atau minuman disini lambungku yang gembel ini terbiasa makan sego taboan ga onok sego pecel a iki yo goblok pisan nang pakuwon gowo rongewu cok goblok muliyo kono cok\",\n",
    "    \"wah jancok kurasa aku sedang melihat sebuah keindahan alam berupa flyover aloha yang sudah bisa diakses alhamdulillah aku terkagum sampai selebrasi ssuuu numpak becak nang pandaan lo lo lo flyover e wes dadi aku jadi semakin bangga menjadi penduduk sidoarjo aku berjanji\",\n",
    "    \"seng kudu mbok lakoni pas ketemu wong kakean basa basi peda taek jancok koen kudu ngiyani tawarane los no ae gak usah sungkan salahe nawari cok gak nge es a mas o yo gelem lawong suroboyo puanas monggo maem ngge purun pak tepak dereng maem kulo beyuh nggatel ayo mas yo ayo mas tepak gabut aku nang endi mas cok kate nang endi tuku sampo mampir sek kene lo ngadem ngadem yo endi kopine cok ndue tamu dijarno ngelak angin senggel maren kiro kiro koen butuh tips bermanfaat opo maneh tulisen nang komentar obat pahit ae nambani mosok kamu seng manis malah ngelarani\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "CJmIW1EQbwSd"
   },
   "outputs": [],
   "source": [
    "# List file audio\n",
    "audio_files = ['audio_1.wav', 'audio_5.wav',]\n",
    "\n",
    "# Referensi transkripsi (gunakan transkripsi referensi yang sesuai)\n",
    "references = [\n",
    "    \"seng kudu mbok lakoni gae njawab pertanyaan ngeri pas lebaran koen kudu menjawab dengan baik ramah dan sopan kapan rabi jancok rame ae jancok jancok kabeh koen kudu menjawab dengan ngegas duduono lek awakmu ngamuk ben wonge wedi kapan lulus koen kudu mengalihkan perhatian kerjomu nang ndi saiki lo jancok penampakan endi cok ini lah penempakan paket seratus ribu kiro kiro koen tips kiro kiro koen butuh tips bermanfaat opo maneh tulis nang komentar ah\",\n",
    "    \"seng kudu mbok lakoni pas ketemu wong kakean basa basi peda taek jancok koen kudu ngiyani tawarane los no ae gak usah sungkan salahe nawari cok gak nge es a mas o yo gelem lawong suroboyo puanas monggo maem ngge purun pak tepak dereng maem kulo beyuh nggatel ayo mas yo ayo mas tepak gabut aku nang endi mas cok kate nang endi tuku sampo mampir sek kene lo ngadem ngadem yo endi kopine cok ndue tamu dijarno ngelak angin senggel maren kiro kiro koen butuh tips bermanfaat opo maneh tulisen nang komentar obat pahit ae nambani mosok kamu seng manis malah ngelarani\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zjyTMF4Eb1mb",
    "outputId": "4c881e92-de21-4f4a-f5f2-e5db752238ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil noise reduction disimpan di: audio_1_reduced_noise.wav\n",
      "Hasil noise reduction disimpan di: audio_5_reduced_noise.wav\n",
      "Transkripsi dengan preprocessing: ['seng gudu mbola koni gae njawab pertanyaan ngeri pas leparan koen kudu menjawab dengan baik rama dan sopan kapen rabi jancok krame kan cok jancok ra ba koen kudu menjawab dengan ngegas didu ono lek awakmu ngamu benwongi wedi kapan lonusuula koen kudu mengalihkan perhatian kerjo munah embi saiki lo gacok penapakan ji cok ndedi la penlambakan pakean seape sribu kiro kiro koen cik seeles dadi mbngapil belappak aokno sekg gurukno kiro kiro koen buduk tik surunan farat opo maneh cules nang gomenter hah', 'seng iku dumboh lakoni pas ketemu wong kakean asap asing gataek cok koen kudu ngi jaki tawarane wasno ae gausaksunga salahe taware cok gak ngesa ma wo yo kelel longsr bae panas banggel maem ga porul pek tepak garek maeng bu lo du ilu gadem hek wan yo ae yo maes tepak gabut aku gandi mas cok gatelaendi tuku sampo mampir sek kele lo ngadenganmu ya endi opine gah cok nde tamu gak elok angin segel kemaren kiro kiro akon buduti rulman fato wo mal dedulese nang komentar obat baeta nambandi mo sok kamuseng manes malan larani']\n",
      "Transkripsi tanpa preprocessing: ['sen gudu mbok la koen igae njawab pertanyaan ngeri pas lebaran koen gudu menjawab dengan baik ramah dan sopan kapen rabi jancok kra mee cancok cancok ra bek koen kudumen jawab dengan ngegas dudu kono oleh awakmu ngamuk baen uwongi wedi kapan lolus ukoen kuduk mengalih kan perhatian kerjo munah endi sa iki lo jancok penampakan bi cok ndene la penambahkan pakean setese ribuk kiro kiro koen tib s terus ga dikongkercol penoko konk ke urukno k kiro koro koen buduk tip surunon fokat opo maneh tules nang komenter e', 'seng kudumbola koni pas ketemu wong kakean baksa basi peda taek cok koen kudungi yani tawarane wasno ae ga usak sungka salae nawari cok ga ngesa mas o yo gelep long sro bae panas bangge maem ga poron pak tepak garek maem ku lo id a iluh jatel ekw yoa yo mas tepak gabut aku mandi mas cok gatila endi tuku sampok mampir sek kene lo ngate ngatemu ya endi kopine gacok nduke tamu jareno lalok angin segel maren kiro kiro koene budutif ruman fa topo malne tulis me nang komentor obat baetan ambane masuk kamu seng manes malang larani']\n",
      "Word Error Rate dengan preprocessing: 0.651685393258427\n",
      "Word Error Rate tanpa preprocessing: 0.6685393258426966\n"
     ]
    }
   ],
   "source": [
    "# Proses semua file audio\n",
    "predictions = []\n",
    "predictions_no_prep = []\n",
    "\n",
    "for file_audio_path in audio_files:\n",
    "    # Proses dengan noise reduction dan volume normalization\n",
    "    reduced_audio_path = file_audio_path.replace('.wav', '_reduced_noise.wav')\n",
    "    reduce_noise(file_audio_path, reduced_audio_path)\n",
    "    audio_array = load_and_preprocess_audio(reduced_audio_path)\n",
    "    transcription = transcribe_audio(audio_array)\n",
    "    predictions.append(transcription)\n",
    "\n",
    "    # Proses tanpa preprocessing\n",
    "    audio_array_no_prep = load_audio(file_audio_path)\n",
    "    transcription_no_prep = transcribe_audio(audio_array_no_prep)\n",
    "    predictions_no_prep.append(transcription_no_prep)\n",
    "\n",
    "# Hitung WER\n",
    "wer = evaluate_wer(predictions, references)\n",
    "wer_no_prep = evaluate_wer(predictions_no_prep, references)\n",
    "\n",
    "# Print hasil\n",
    "print(\"Transkripsi dengan preprocessing:\", predictions)\n",
    "print(\"Transkripsi tanpa preprocessing:\", predictions_no_prep)\n",
    "print(\"Word Error Rate dengan preprocessing:\", wer)\n",
    "print(\"Word Error Rate tanpa preprocessing:\", wer_no_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hWXQk8CBtu7Z",
    "outputId": "cc6e704e-bbdc-49b5-f291-ce3488cf9901"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seng gudu mbola koni gae njawab pertanyaan ngeri pas leparan koen kudu menjawab dengan baik rama dan sopan kapen rabi jancok krame kan cok jancok ra ba koen kudu menjawab dengan ngegas didu ono lek awakmu ngamu benwongi wedi kapan lonusuula koen kudu mengalihkan perhatian kerjo munah embi saiki lo gacok penapakan ji cok ndedi la penlambakan pakean seape sribu kiro kiro koen cik seeles dadi mbngapil belappak aokno sekg gurukno kiro kiro koen buduk tik surunan farat opo maneh cules nang gomenter hah',\n",
       " 'seng iku dumboh lakoni pas ketemu wong kakean asap asing gataek cok koen kudu ngi jaki tawarane wasno ae gausaksunga salahe taware cok gak ngesa ma wo yo kelel longsr bae panas banggel maem ga porul pek tepak garek maeng bu lo du ilu gadem hek wan yo ae yo maes tepak gabut aku gandi mas cok gatelaendi tuku sampo mampir sek kele lo ngadenganmu ya endi opine gah cok nde tamu gak elok angin segel kemaren kiro kiro akon buduti rulman fato wo mal dedulese nang komentar obat baeta nambandi mo sok kamuseng manes malan larani']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eC8wXeE2dEnj"
   },
   "source": [
    "#**Percobaan sesungguhnya**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YLhObdiadLER"
   },
   "outputs": [],
   "source": [
    "# Kamus kata-kata vulgar (contoh)\n",
    "vulgar_words = {\"asu\", \"jancok\", \"cok\",\"goblog\",\"nggateli\",\n",
    "                \"nggatel\",\"dancok\",\"hancok\",\"ancok\",\"ngentot\",\n",
    "                \"taek\",\"goblok\",\"tolol\",\"kontol\",\"jangkrek\",\n",
    "                \"silit\",\"bajingan\",\"anjing\",\"jembut\",\"longor\"}\n",
    "# Fungsi untuk mendeteksi kata kasar\n",
    "def detect_profanity(text, profanity_list):\n",
    "    words = text.split()\n",
    "    profane_words = [word for word in words if word.lower() in profanity_list]\n",
    "    return profane_words, words\n",
    "\n",
    "# Fungsi untuk memperkirakan waktu kemunculan kata dalam audio\n",
    "def get_profanity_timestamps(profane_words, words, audio_duration):\n",
    "    profanity_timestamps = []\n",
    "    word_duration = audio_duration / len(words)  # Durasi rata-rata tiap kata\n",
    "\n",
    "    # Gunakan set untuk menyimpan kata-kata kasar yang sudah terdeteksi\n",
    "    detected_set = set()\n",
    "\n",
    "    for word in profane_words:\n",
    "        if word.lower() not in detected_set:\n",
    "            word_indices = [i for i, w in enumerate(words) if w.lower() == word]\n",
    "            for idx in word_indices:\n",
    "                word_time = idx * word_duration\n",
    "                profanity_timestamps.append((word, word_time))\n",
    "            # Tambahkan kata ke set untuk menandai bahwa sudah terdeteksi\n",
    "            detected_set.add(word.lower())\n",
    "\n",
    "    return profanity_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1rh_158LdUHJ"
   },
   "outputs": [],
   "source": [
    "# Deteksi kata-kata vulgar\n",
    "detected_vulgar_words, words = detect_profanity(transcription, vulgar_words)\n",
    "\n",
    "# Dapatkan durasi audio\n",
    "audio_segment = AudioSegment.from_file(audio_path)\n",
    "audio_duration = len(audio_segment) / 1000.0  # Durasi dalam detik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "67BNUsv1VFWR",
    "outputId": "f157f393-ab49-4c0d-b0ad-4dea4a0e3664"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jancok', 'cok', 'jancok', 'cok']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detected_vulgar_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wYO0EX6XdrGx",
    "outputId": "f9bb43c8-e8d7-41ee-b990-4eebf5e6a6ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waktu munculnya kata-kata vulgar dalam detik:\n",
      "'jancok' pada detik ke-10.46\n",
      "'jancok' pada detik ke-12.55\n",
      "'cok' pada detik ke-12.03\n",
      "'cok' pada detik ke-27.72\n"
     ]
    }
   ],
   "source": [
    "# Deteksi waktu munculnya kata-kata vulgar dalam audio\n",
    "profanity_timestamps = get_profanity_timestamps(detected_vulgar_words, words, audio_duration)\n",
    "print(\"Waktu munculnya kata-kata vulgar dalam detik:\")\n",
    "for word, time_seconds in profanity_timestamps:\n",
    "    print(f\"'{word}' pada detik ke-{time_seconds:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CHmRLuBydvEp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
